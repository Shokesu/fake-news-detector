{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              title  \\\n",
      "0           0  20 imagens que, por incrível que pareça, não s...   \n",
      "1           1  24 filmes da Disney explicados por homens que ...   \n",
      "2           2  Todo mundo é uma princesa da Disney OU um heró...   \n",
      "3           3  Quais são as três comidas que combinam com a s...   \n",
      "4           4  Este teste sobre comida vai dizer de uma vez p...   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.buzzfeed.com/daves4/animais-penis-...  \n",
      "1  https://www.buzzfeed.com/keelyflaherty/filmes-...  \n",
      "2  https://www.buzzfeed.com/perpetua/teste-prince...  \n",
      "3  https://www.buzzfeed.com/joannaborns/teste-tre...  \n",
      "4  https://www.buzzfeed.com/joannaborns/teste-com...  \n",
      "   Unnamed: 0                                              title  \\\n",
      "0           0  Nem todos que assinam manifesto pró-Boulos dec...   \n",
      "1           1  Centenas de professores universitários não est...   \n",
      "2           2  Janaina Paschoal diz que ser vice de Bolsonaro...   \n",
      "3           3  Russomanno vira sócio de startup financeira qu...   \n",
      "4           4  Governo errou na política para combustíveis, d...   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.buzzfeed.com/tatianafarah/frei-bet...  \n",
      "1  https://www.buzzfeed.com/felitti/centenas-de-p...  \n",
      "2  https://www.buzzfeed.com/tatianafarah/janaina-...  \n",
      "3  https://www.buzzfeed.com/alexandrearagao/russo...  \n",
      "4  https://www.buzzfeed.com/severinomotta/governo...  \n",
      "                                                   0\n",
      "0                                 Should I Get Bings\n",
      "1      Which TV Female Friend Group Do You Belong In\n",
      "2  The New \"Star Wars: The Force Awakens\" Trailer...\n",
      "3  This Vine Of New York On \"Celebrity Big Brothe...\n",
      "4  A Couple Did A Stunning Photo Shoot With Their...\n",
      "                                                   0\n",
      "0  Bill Changing Credit Card Rules Is Sent to Oba...\n",
      "1  In Hollywood, the Easy-Money Generation Toughe...\n",
      "2  1700 runners still unaccounted for in UK's Lak...\n",
      "3  Yankees Pitchers Trade Fielding Drills for Put...\n",
      "4  Large earthquake rattles Indonesia; Seventh in...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category_id</th>\n",
       "      <th>clickbait_title</th>\n",
       "      <th>content</th>\n",
       "      <th>count</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>verified_category_id</th>\n",
       "      <th>verified_clickbait_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tweet\\n\\nThe Environmental Protection Agency (...</td>\n",
       "      <td>1</td>\n",
       "      <td>2078</td>\n",
       "      <td>Wolf in Sheep’s Clothing (or a Scientist’s Lab...</td>\n",
       "      <td>http://www.pogo.org/blog/2018/05/wolf_in_sheep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Reveja todos os finais de 'O Outro Lado'\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>2077</td>\n",
       "      <td>globo.com - Absolutamente tudo sobre notícias,...</td>\n",
       "      <td>https://www.globo.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A black Yale student was taking a nap in a com...</td>\n",
       "      <td>1</td>\n",
       "      <td>2076</td>\n",
       "      <td>White people keep calling the cops on black pe...</td>\n",
       "      <td>https://www.vox.com/identities/2018/5/11/17340...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday afternoon, the Justice Department relea...</td>\n",
       "      <td>1</td>\n",
       "      <td>2075</td>\n",
       "      <td>Donald Trump, Bernie Sanders, and Jill Stein a...</td>\n",
       "      <td>https://www.vox.com/policy-and-politics/2018/2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I regularly attend an annual security conferen...</td>\n",
       "      <td>1</td>\n",
       "      <td>2074</td>\n",
       "      <td>John McCain: ‘Vladimir Putin Is an Evil Man’</td>\n",
       "      <td>https://www.wsj.com/articles/john-mccain-vladi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  category_id  clickbait_title  \\\n",
       "0           0            1              0.0   \n",
       "1           1            1              0.0   \n",
       "2           2            1              NaN   \n",
       "3           3            1              NaN   \n",
       "4           4            1              0.0   \n",
       "\n",
       "                                             content  count    id  \\\n",
       "0  Tweet\\n\\nThe Environmental Protection Agency (...      1  2078   \n",
       "1         Reveja todos os finais de 'O Outro Lado'\\n      1  2077   \n",
       "2  A black Yale student was taking a nap in a com...      1  2076   \n",
       "3  Friday afternoon, the Justice Department relea...      1  2075   \n",
       "4  I regularly attend an annual security conferen...      1  2074   \n",
       "\n",
       "                                               title  \\\n",
       "0  Wolf in Sheep’s Clothing (or a Scientist’s Lab...   \n",
       "1  globo.com - Absolutamente tudo sobre notícias,...   \n",
       "2  White people keep calling the cops on black pe...   \n",
       "3  Donald Trump, Bernie Sanders, and Jill Stein a...   \n",
       "4       John McCain: ‘Vladimir Putin Is an Evil Man’   \n",
       "\n",
       "                                                 url  verified_category_id  \\\n",
       "0  http://www.pogo.org/blog/2018/05/wolf_in_sheep...                   NaN   \n",
       "1                             https://www.globo.com/                   NaN   \n",
       "2  https://www.vox.com/identities/2018/5/11/17340...                   NaN   \n",
       "3  https://www.vox.com/policy-and-politics/2018/2...                   NaN   \n",
       "4  https://www.wsj.com/articles/john-mccain-vladi...                   NaN   \n",
       "\n",
       "   verified_clickbait_title  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "buzzfeedbr_clickbait_titles = pd.read_csv(\"../train_data/buzzfeedbr/clickbait_titles.csv\")\n",
    "print(buzzfeedbr_clickbait_titles[0:5])\n",
    "\n",
    "buzzfeedbr_non_clickbait_titles = pd.read_csv(\"../train_data/buzzfeedbr/non_clickbait_titles.csv\")\n",
    "print(buzzfeedbr_non_clickbait_titles[0:5])\n",
    "\n",
    "clickbait_titles = pd.read_csv(\"../train_data/bhargaviparanjape/clickbait_data.csv\", sep=\"\\n\", header=None)\n",
    "print(clickbait_titles[0:5])\n",
    "\n",
    "non_clickbait_titles = pd.read_csv(\"../train_data/bhargaviparanjape/non_clickbait_data.csv\", sep=\"\\n\", header=None)\n",
    "print(non_clickbait_titles[0:5])\n",
    "\n",
    "all_links = pd.read_csv(\"../train_data/links.csv\")\n",
    "all_links[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of click bait samples 164\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pay Little Wanderers NYC using PayPal.Me</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evangelical Christian Radio Host Says Nothing ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did Armed Trump Supporters Ask a Navajo Legisl...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'SPYGATE': Trump ramps up attacks on FBI, Russ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Top intel official says Chinese ZTE cellphones...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lesley Stahl: Trump admitted mission to \"discr...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tomi Lahren Gets Owned By Genealogist After He...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMH: Tomi Lahren Gets A Drink Thrown At Her At...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trump's norm-breaking is leading to a constitu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Richard Painter says there is more evidence ag...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Theory: Playboy Model Had Affair With Trump, N...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jared Kushner’s startup is seeking $100 millio...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Judge’s contempt finding on Kobach still stand...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Is this Playboy model keeping the biggest secr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A Venezuela é palco de uma batalha global deci...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Conheça a mulher por trás da série Cosmos</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lazzo Matumbi fala sobre 'Atrás do Por do Sol'...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MBL - Movimento Brasil Livre - Página inicial</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Top 10 Mysterious Things Found Frozen In Ice A...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>O mito do uso de 10% do cérebro</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Neil deGrasse Tyson diz que seu novo vídeo tal...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I am excited to start the European part of my ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Congratulations, Kyle Kashuv! No. 1 in his cla...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Donna abruzzese lascia 3 milioni di euro a Sil...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Crowd Cheers As 93-Year-Old Fuckup Finally Gra...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Joe Rogan - Adolf Hitler Escaped To South Amer...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Georgia 2018: Hillary Clinton endorses Abrams ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Teste feito por equipe da Unicamp revelou falh...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RNC paid nearly half a million dollars to law ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Trump to Demand Investigation Into Whether FBI...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>8 truques que os pintores de paredes não conta...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>O atentado de Janaúba que dilacerou a vida de ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>A trajetória das tarifas de energia nos último...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>Google Pixel 2 terá atualizações do Android e ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>Tyrese Congratulates The Rock For Ruining The ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>Em feira de Luisa Mell, pessoas vão embora ao ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>O apocalipse foi apenas adiado no novo trailer...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>Woman Gives Birth In Japan, Shows What Food Sh...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>Comer de Graça no Zaffari, Beringela Baby e Xi...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>Como a queda da Selic vai afetar a poupança</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>Firefox faz mudança no logo para marcar uso do...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>Como cientistas criaram um algoritmo que ‘prod...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>TIM aumenta internet no pós-pago com bônus de ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>Acusado de matar travesti é absolvido em 1° jú...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>Em 10 anos, aprender a usar emojis será mais i...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>Receber mais curtidas na sua foto criança no F...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>Celulares começam a ser vendidos com outro apa...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>Após artigo de general defendendo golpe, Estad...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>Grupo sequestra Obama e só o libera se ele se ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>Estado Islâmico assume plástica de Ivana Trump</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>Após temporada na Coreia, censura fará turnê n...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>Facebook retira comentários e deixa apenas bot...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>Mudança na Rouanet proíbe a Bíblia, que está c...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>Kesha falou sobre que tipo de amiga a Taylor S...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>Em silêncio, reforma eleitoral criou censura n...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>Mulher acusa laboratório Fleury de racismo por...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>A hashtag #posteseuviralata está enchendo o Tw...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>Site Lança Cardápio Fit (low-carb) e é Nova Se...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>15 destinos para conhecer de trem</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>STF decide hoje se vídeo de Aécio explicando m...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  is_clickbait\n",
       "0              Pay Little Wanderers NYC using PayPal.Me           0.5\n",
       "1     Evangelical Christian Radio Host Says Nothing ...           0.0\n",
       "2     Did Armed Trump Supporters Ask a Navajo Legisl...           0.0\n",
       "3     'SPYGATE': Trump ramps up attacks on FBI, Russ...           0.5\n",
       "4     Top intel official says Chinese ZTE cellphones...           0.5\n",
       "5     Lesley Stahl: Trump admitted mission to \"discr...           0.5\n",
       "6     Tomi Lahren Gets Owned By Genealogist After He...           1.0\n",
       "7     SMH: Tomi Lahren Gets A Drink Thrown At Her At...           0.5\n",
       "9     Trump's norm-breaking is leading to a constitu...           0.0\n",
       "10    Richard Painter says there is more evidence ag...           0.5\n",
       "11    Theory: Playboy Model Had Affair With Trump, N...           0.5\n",
       "12    Jared Kushner’s startup is seeking $100 millio...           0.5\n",
       "13    Judge’s contempt finding on Kobach still stand...           0.5\n",
       "14    Is this Playboy model keeping the biggest secr...           0.0\n",
       "15    A Venezuela é palco de uma batalha global deci...           1.0\n",
       "16            Conheça a mulher por trás da série Cosmos           0.0\n",
       "17    Lazzo Matumbi fala sobre 'Atrás do Por do Sol'...           0.0\n",
       "18        MBL - Movimento Brasil Livre - Página inicial           1.0\n",
       "19    Top 10 Mysterious Things Found Frozen In Ice A...           1.0\n",
       "20                      O mito do uso de 10% do cérebro           0.0\n",
       "21    Neil deGrasse Tyson diz que seu novo vídeo tal...           0.0\n",
       "22    I am excited to start the European part of my ...           0.0\n",
       "23    Congratulations, Kyle Kashuv! No. 1 in his cla...           0.5\n",
       "24    Donna abruzzese lascia 3 milioni di euro a Sil...           1.0\n",
       "25    Crowd Cheers As 93-Year-Old Fuckup Finally Gra...           1.0\n",
       "26    Joe Rogan - Adolf Hitler Escaped To South Amer...           1.0\n",
       "27    Georgia 2018: Hillary Clinton endorses Abrams ...           0.5\n",
       "28    Teste feito por equipe da Unicamp revelou falh...           0.0\n",
       "29    RNC paid nearly half a million dollars to law ...           0.0\n",
       "30    Trump to Demand Investigation Into Whether FBI...           0.5\n",
       "...                                                 ...           ...\n",
       "2089  8 truques que os pintores de paredes não conta...           1.0\n",
       "2090  O atentado de Janaúba que dilacerou a vida de ...           0.5\n",
       "2091  A trajetória das tarifas de energia nos último...           0.5\n",
       "2092  Google Pixel 2 terá atualizações do Android e ...           0.5\n",
       "2093  Tyrese Congratulates The Rock For Ruining The ...           0.5\n",
       "2094  Em feira de Luisa Mell, pessoas vão embora ao ...           0.5\n",
       "2095  O apocalipse foi apenas adiado no novo trailer...           0.5\n",
       "2096  Woman Gives Birth In Japan, Shows What Food Sh...           1.0\n",
       "2097  Comer de Graça no Zaffari, Beringela Baby e Xi...           0.5\n",
       "2098        Como a queda da Selic vai afetar a poupança           0.5\n",
       "2099  Firefox faz mudança no logo para marcar uso do...           0.5\n",
       "2100  Como cientistas criaram um algoritmo que ‘prod...           0.5\n",
       "2101  TIM aumenta internet no pós-pago com bônus de ...           0.5\n",
       "2102  Acusado de matar travesti é absolvido em 1° jú...           0.5\n",
       "2103  Em 10 anos, aprender a usar emojis será mais i...           0.5\n",
       "2104  Receber mais curtidas na sua foto criança no F...           0.5\n",
       "2105  Celulares começam a ser vendidos com outro apa...           0.5\n",
       "2106  Após artigo de general defendendo golpe, Estad...           0.5\n",
       "2107  Grupo sequestra Obama e só o libera se ele se ...           0.5\n",
       "2108     Estado Islâmico assume plástica de Ivana Trump           0.5\n",
       "2109  Após temporada na Coreia, censura fará turnê n...           0.5\n",
       "2110  Facebook retira comentários e deixa apenas bot...           0.5\n",
       "2111  Mudança na Rouanet proíbe a Bíblia, que está c...           0.5\n",
       "2112  Kesha falou sobre que tipo de amiga a Taylor S...           1.0\n",
       "2113  Em silêncio, reforma eleitoral criou censura n...           0.5\n",
       "2115  Mulher acusa laboratório Fleury de racismo por...           0.5\n",
       "2116  A hashtag #posteseuviralata está enchendo o Tw...           0.5\n",
       "2117  Site Lança Cardápio Fit (low-carb) e é Nova Se...           1.0\n",
       "2118                  15 destinos para conhecer de trem           0.5\n",
       "2119  STF decide hoje se vídeo de Aécio explicando m...           0.5\n",
       "\n",
       "[1314 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "df = all_links.copy()\n",
    "\n",
    "df['title'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=[\"title\"], inplace=True)\n",
    "df = df.loc[df['title'].str.len() > 30]\n",
    "\n",
    "df[\"clickbait_title\"] = df['verified_clickbait_title'].fillna(df['clickbait_title'])\n",
    "\n",
    "df[\"is_clickbait\"] = [ 0 if c == 0 else 1 if c == 1 else 0.5 for c in df['clickbait_title'] ]\n",
    "\n",
    "df = df[[\"title\", \"is_clickbait\"]]\n",
    "\n",
    "print(\"Number of click bait samples\", len(df[df[\"is_clickbait\"] == 1]))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default classification approach, ignoring \"I don't know\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:    7.1s finished\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>tfidf__max_df</th>\n",
       "      <th>tfidf__min_df</th>\n",
       "      <th>tfidf__token_pattern</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.620094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.624098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.630742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.624223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.623281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.614153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.621734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.606199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.347618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.340246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.554712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.522511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.402266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.197693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.516835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.545901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  clf  tfidf__max_df  \\\n",
       "0   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.5   \n",
       "1   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.5   \n",
       "2   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.5   \n",
       "3   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.5   \n",
       "4   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.1   \n",
       "5   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.1   \n",
       "6   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.1   \n",
       "7   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.1   \n",
       "8   (DecisionTreeClassifier(class_weight=None, cri...            0.5   \n",
       "9   (DecisionTreeClassifier(class_weight=None, cri...            0.5   \n",
       "10  (DecisionTreeClassifier(class_weight=None, cri...            0.5   \n",
       "11  (DecisionTreeClassifier(class_weight=None, cri...            0.5   \n",
       "12  (DecisionTreeClassifier(class_weight=None, cri...            0.1   \n",
       "13  (DecisionTreeClassifier(class_weight=None, cri...            0.1   \n",
       "14  (DecisionTreeClassifier(class_weight=None, cri...            0.1   \n",
       "15  (DecisionTreeClassifier(class_weight=None, cri...            0.1   \n",
       "16  DummyClassifier(constant=1.0, random_state=Non...            0.5   \n",
       "17  DummyClassifier(constant=1.0, random_state=Non...            0.5   \n",
       "18  DummyClassifier(constant=1.0, random_state=Non...            0.5   \n",
       "19  DummyClassifier(constant=1.0, random_state=Non...            0.5   \n",
       "20  DummyClassifier(constant=1.0, random_state=Non...            0.1   \n",
       "21  DummyClassifier(constant=1.0, random_state=Non...            0.1   \n",
       "22  DummyClassifier(constant=1.0, random_state=Non...            0.1   \n",
       "23  DummyClassifier(constant=1.0, random_state=Non...            0.1   \n",
       "\n",
       "    tfidf__min_df tfidf__token_pattern  mean_test_score  \n",
       "0               1         [A-Za-z0-9]+         0.620094  \n",
       "1               1        (?u)\\b\\w\\w+\\b         0.624098  \n",
       "2               2         [A-Za-z0-9]+         0.630742  \n",
       "3               2        (?u)\\b\\w\\w+\\b         0.624223  \n",
       "4               1         [A-Za-z0-9]+         0.623281  \n",
       "5               1        (?u)\\b\\w\\w+\\b         0.614153  \n",
       "6               2         [A-Za-z0-9]+         0.621734  \n",
       "7               2        (?u)\\b\\w\\w+\\b         0.606199  \n",
       "8               1         [A-Za-z0-9]+         0.347618  \n",
       "9               1        (?u)\\b\\w\\w+\\b         0.340246  \n",
       "10              2         [A-Za-z0-9]+         0.554712  \n",
       "11              2        (?u)\\b\\w\\w+\\b         0.522511  \n",
       "12              1         [A-Za-z0-9]+         0.402266  \n",
       "13              1        (?u)\\b\\w\\w+\\b         0.197693  \n",
       "14              2         [A-Za-z0-9]+         0.516835  \n",
       "15              2        (?u)\\b\\w\\w+\\b         0.545901  \n",
       "16              1         [A-Za-z0-9]+         0.666667  \n",
       "17              1        (?u)\\b\\w\\w+\\b         0.666667  \n",
       "18              2         [A-Za-z0-9]+         0.666667  \n",
       "19              2        (?u)\\b\\w\\w+\\b         0.666667  \n",
       "20              1         [A-Za-z0-9]+         0.666667  \n",
       "21              1        (?u)\\b\\w\\w+\\b         0.666667  \n",
       "22              2         [A-Za-z0-9]+         0.666667  \n",
       "23              2        (?u)\\b\\w\\w+\\b         0.666667  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "positive_df = df[df[\"is_clickbait\"] == 1]\n",
    "negative_df = df[df[\"is_clickbait\"] == 0].apply(np.random.permutation)[0:len(positive_df)]\n",
    "balanced_df = positive_df.append(negative_df)\n",
    "balanced_df = balanced_df.reindex(np.random.permutation(balanced_df.index))\n",
    "\n",
    "X = balanced_df\n",
    "y = balanced_df[\"is_clickbait\"]\n",
    "y = [ False if yi == 0 else True for yi in y ]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x: x['title'], validate=False)),\n",
    "    ('tfidf', TfidfVectorizer(strip_accents='ascii', ngram_range=(1, 3), max_df=0.5, min_df=2, token_pattern='[A-Za-z0-9]+')),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "clf = GridSearchCV(pipeline, verbose=1, scoring='f1', param_grid={\n",
    "    'clf': [\n",
    "        MultinomialNB(),\n",
    "        RandomForestClassifier(),\n",
    "        DummyClassifier(\"constant\", constant=1.0)\n",
    "    ],\n",
    "    'tfidf__max_df': [0.5, 0.1],\n",
    "    'tfidf__min_df': [1, 2],\n",
    "    'tfidf__token_pattern': ['[A-Za-z0-9]+', r\"(?u)\\b\\w\\w+\\b\"]\n",
    "})\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "results = pd.DataFrame(clf.cv_results_)\n",
    "results['clf'] = [ p['clf'] for p in results['params'] ]\n",
    "results['tfidf__max_df'] = [ p['tfidf__max_df'] for p in results['params'] ]\n",
    "results['tfidf__min_df'] = [ p['tfidf__min_df'] for p in results['params'] ]\n",
    "results['tfidf__token_pattern'] = [ p['tfidf__token_pattern'] for p in results['params'] ]\n",
    "results[['clf', 'tfidf__max_df', 'tfidf__min_df', 'tfidf__token_pattern', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor Appoach, taking \"I don't know\" into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>facts about the iss - Google Search</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>O que espanta no caso de Marcelo Sereno - O An...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Tout ce qu'il faut savoir pour prendre soin d'...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Pyongyang ne renoncera jamais entièrement à se...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>Fato inédito na história do Barça!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Lula joga a toalha - O Antagonista</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Hillary Clinton: Destroy Syria for Israel: « T...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>SATURDAY OF LAZARUS by Archpriest Timothy Crem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Edit: FOI AGREDIDO, NÃO! AGREDIU VERBALMENTE P...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Artistas da lacração socialista: Pabllo Vittar...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>🚨🚨 No Consuman Estos Productos Gracias .🚨🚨 COM...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>#FORÇALULA ♥ Curta Geração Coca-Cola</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Brad Marchand réplique au Canadien sur Twitter...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Effects of Climate Change ‘Irreversible,’ U.N....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Gleisi Hoffmann dá o recado: Lula é o nosso ca...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Billionaires made enough money in 2017 to end ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Comer de Graça no Zaffari, Beringela Baby e Xi...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>Fake News Detector - Chrome Web Store</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Sal do himalaia faz mal? Descubra agora | Corp...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Quick-thinking Mom Saves Family’s Life By Givi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Alice Paquet réagit aux révélations de la nouv...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>Vazou áudio no whatsapp contra o Galo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>Mozilla Joins George Soros's Efforts In Launch...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Har du Rh-negativt blod? Du kan vara en utomjo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Receber mais curtidas na sua foto criança no F...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Candidatos terão ‘trégua’ da Lava Jato até fim...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>Will You Be Happy Or Unhappy In 2018?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>O Estado não gosta de concorrência ;)</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>The New Doctor Who: 8 Things We Know (And 7 Cr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Alek Minassian: 5 Fast Facts You Need to Know ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Heat on Stormy Daniels' lawyer over past busin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Il faut redonner à la vie politique ses lettre...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Eliane Cantanhêde diz que cubanos estão chegan...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>The Bible Says The World Is Going To End On Ju...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Telegram agora permite compartilhar sua locali...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>This Man Has Kept an Unopened Christmas Presen...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Avião joga veneno sobre famílias de sem terra ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>Por que Dona Regina esmagou esquerdistas apena...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Entrevista com Selton Mello | The Noite (21/03...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Uma tasca autêntica, com direito à mesa na cal...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>Amazon Go: Retail Store of the Future</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>Procuradoria espanhola solicita cadeia para jo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Rajoy confunde al primer ministro danés con el...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>Só pessoas com olhos de águia conseguirão enco...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Facebook stops putting \"Disputed Flags\" on fak...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Sheriff: Secret Service investigating vandalis...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Warcraft Logs - Combat Analysis for Warcraft</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>‘Hurting us more than he knows’: The steelwork...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Robert Mueller is on @TIME's list of the world...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Leilão novos e usados: Santorini+Exp, Lost Leg...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>I'm sorry I had to cancel the first 5 recitals...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Catalunya se llena de adoquines en memoria de ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>É isto o que os seus olhos revelam sobre sua a...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>TOP 10 animais BIZARROS que de fato existem ou...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Jim Carrey Slammed By Fox News For 'Disgracefu...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Have scientists really admitted climate change...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>The recent mobilizations in the city of Jerada...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Tina Fey defends Michelle Wolf and has a sugge...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Caso Lula: Jurista diz que prisão após segunda...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>EXCLUSIVE: Robert Mercer backed a secretive gr...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  is_clickbait\n",
       "1552                facts about the iss - Google Search           1.0\n",
       "185   O que espanta no caso de Marcelo Sereno - O An...           0.0\n",
       "144   Tout ce qu'il faut savoir pour prendre soin d'...           0.0\n",
       "89    Pyongyang ne renoncera jamais entièrement à se...           1.0\n",
       "2046                 Fato inédito na história do Barça!           1.0\n",
       "290                  Lula joga a toalha - O Antagonista           0.0\n",
       "32    Hillary Clinton: Destroy Syria for Israel: « T...           1.0\n",
       "221   SATURDAY OF LAZARUS by Archpriest Timothy Crem...           0.0\n",
       "180   Edit: FOI AGREDIDO, NÃO! AGREDIU VERBALMENTE P...           0.0\n",
       "431   Artistas da lacração socialista: Pabllo Vittar...           0.5\n",
       "146   🚨🚨 No Consuman Estos Productos Gracias .🚨🚨 COM...           1.0\n",
       "317                #FORÇALULA ♥ Curta Geração Coca-Cola           0.5\n",
       "142   Brad Marchand réplique au Canadien sur Twitter...           1.0\n",
       "331   Effects of Climate Change ‘Irreversible,’ U.N....           0.0\n",
       "167   Gleisi Hoffmann dá o recado: Lula é o nosso ca...           0.0\n",
       "427   Billionaires made enough money in 2017 to end ...           0.5\n",
       "479   Comer de Graça no Zaffari, Beringela Baby e Xi...           0.5\n",
       "1755              Fake News Detector - Chrome Web Store           1.0\n",
       "456   Sal do himalaia faz mal? Descubra agora | Corp...           0.5\n",
       "79    Quick-thinking Mom Saves Family’s Life By Givi...           1.0\n",
       "170   Alice Paquet réagit aux révélations de la nouv...           0.0\n",
       "1807              Vazou áudio no whatsapp contra o Galo           1.0\n",
       "1603  Mozilla Joins George Soros's Efforts In Launch...           1.0\n",
       "171   Har du Rh-negativt blod? Du kan vara en utomjo...           1.0\n",
       "81    Receber mais curtidas na sua foto criança no F...           0.5\n",
       "241   Candidatos terão ‘trégua’ da Lava Jato até fim...           1.0\n",
       "1660              Will You Be Happy Or Unhappy In 2018?           1.0\n",
       "58                O Estado não gosta de concorrência ;)           0.5\n",
       "1862  The New Doctor Who: 8 Things We Know (And 7 Cr...           1.0\n",
       "373   Alek Minassian: 5 Fast Facts You Need to Know ...           0.0\n",
       "...                                                 ...           ...\n",
       "36    Heat on Stormy Daniels' lawyer over past busin...           0.0\n",
       "28    Il faut redonner à la vie politique ses lettre...           0.0\n",
       "470   Eliane Cantanhêde diz que cubanos estão chegan...           1.0\n",
       "282   The Bible Says The World Is Going To End On Ju...           0.5\n",
       "106   Telegram agora permite compartilhar sua locali...           0.5\n",
       "1654  This Man Has Kept an Unopened Christmas Presen...           1.0\n",
       "38    Avião joga veneno sobre famílias de sem terra ...           0.5\n",
       "2059  Por que Dona Regina esmagou esquerdistas apena...           1.0\n",
       "333   Entrevista com Selton Mello | The Noite (21/03...           0.0\n",
       "372   Uma tasca autêntica, com direito à mesa na cal...           0.0\n",
       "1518              Amazon Go: Retail Store of the Future           1.0\n",
       "771   Procuradoria espanhola solicita cadeia para jo...           1.0\n",
       "184   Rajoy confunde al primer ministro danés con el...           0.0\n",
       "1972  Só pessoas com olhos de águia conseguirão enco...           1.0\n",
       "271   Facebook stops putting \"Disputed Flags\" on fak...           0.5\n",
       "152   Sheriff: Secret Service investigating vandalis...           0.0\n",
       "107        Warcraft Logs - Combat Analysis for Warcraft           0.0\n",
       "411   ‘Hurting us more than he knows’: The steelwork...           0.5\n",
       "260   Robert Mueller is on @TIME's list of the world...           0.0\n",
       "76    Leilão novos e usados: Santorini+Exp, Lost Leg...           0.5\n",
       "101   I'm sorry I had to cancel the first 5 recitals...           0.0\n",
       "252   Catalunya se llena de adoquines en memoria de ...           0.5\n",
       "110   É isto o que os seus olhos revelam sobre sua a...           0.5\n",
       "632   TOP 10 animais BIZARROS que de fato existem ou...           1.0\n",
       "268   Jim Carrey Slammed By Fox News For 'Disgracefu...           0.5\n",
       "351   Have scientists really admitted climate change...           0.0\n",
       "359   The recent mobilizations in the city of Jerada...           0.0\n",
       "263   Tina Fey defends Michelle Wolf and has a sugge...           0.0\n",
       "300   Caso Lula: Jurista diz que prisão após segunda...           0.5\n",
       "461   EXCLUSIVE: Robert Mercer backed a secretive gr...           0.5\n",
       "\n",
       "[492 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df = df[df[\"is_clickbait\"] == 1]\n",
    "negative_df = df[df[\"is_clickbait\"] == 0].apply(np.random.permutation)[0:len(positive_df)]\n",
    "idk_df = df[(df[\"is_clickbait\"] != 0) & (df[\"is_clickbait\"] != 1)].apply(np.random.permutation)[0:len(positive_df)]\n",
    "balanced_df = positive_df.append(negative_df).append(idk_df)\n",
    "balanced_df = balanced_df.reindex(np.random.permutation(balanced_df.index))\n",
    "\n",
    "X = balanced_df\n",
    "y = balanced_df[\"is_clickbait\"]\n",
    "\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8eca88a6d5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m            ]\n\u001b[1;32m     68\u001b[0m })\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m--> 108\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, recall_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn import linear_model\n",
    "\n",
    "class ModelTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        self.model.fit(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return pd.DataFrame(self.model.predict(X))\n",
    "\n",
    "class RoundTransformer(BaseEstimator):\n",
    "    def __init__(self, limit=0.5):\n",
    "        self.limit = limit\n",
    "        \n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return [ 1.0 if x >= self.limit else 0.0 for x in X[0] ]\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # Ignore the \"i don't know\" click bait titles for scoring later,\n",
    "        # because even if the humans are not sure, it is not a problem for\n",
    "        # the machine to be wrong\n",
    "        y = pd.Series(y).reset_index(drop=True)\n",
    "        indexes = y.index[(y != 0.5)].tolist()\n",
    "        X_test = X.loc[indexes]\n",
    "        y_test = y.loc[indexes]\n",
    "\n",
    "        if len(y_test) == 0:\n",
    "            return 0\n",
    "        \n",
    "        score = accuracy_score(self.predict(X_test), y_test)\n",
    "        return score\n",
    "    \n",
    "pipeline = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x: x['title'], validate=False)),\n",
    "    ('tfidf', TfidfVectorizer(strip_accents='ascii', ngram_range=(1, 3), max_df=0.5, min_df=2)),\n",
    "    ('clf', ModelTransformer(RandomForestRegressor())),\n",
    "    ('round', RoundTransformer(limit=0.5))\n",
    "])\n",
    "\n",
    "clf = GridSearchCV(pipeline, verbose=1, scoring='f1', param_grid={\n",
    "    'round__limit': [0.5, 0.7, 0.3],\n",
    "    'clf': [ModelTransformer(DummyClassifier(\"constant\", constant=1.0)),\n",
    "            ModelTransformer(RandomForestRegressor()),\n",
    "            ModelTransformer(linear_model.LinearRegression()),\n",
    "            ModelTransformer(linear_model.Ridge()),\n",
    "            ModelTransformer(linear_model.ElasticNet()),\n",
    "#             ModelTransformer(linear_model.LassoLars()),\n",
    "#             ModelTransformer(linear_model.OrthogonalMatchingPursuit()),\n",
    "#             ModelTransformer(linear_model.BayesianRidge()),\n",
    "#             ModelTransformer(linear_model.ARDRegression()),\n",
    "#             ModelTransformer(linear_model.LogisticRegression()),\n",
    "#             ModelTransformer(linear_model.SGDRegressor()),\n",
    "            ModelTransformer(linear_model.PassiveAggressiveRegressor()),\n",
    "#             ModelTransformer(linear_model.TheilSenRegressor()),\n",
    "            ModelTransformer(linear_model.HuberRegressor()),\n",
    "#             ModelTransformer(linear_model.RANSACRegressor()),\n",
    "            ModelTransformer(linear_model.Lasso())\n",
    "           ]\n",
    "})\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "results = pd.DataFrame(clf.cv_results_)\n",
    "results['clf'] = [ p['clf'] for p in results['params'] ]\n",
    "results['round__limit'] = [ p['round__limit'] for p in results['params'] ]\n",
    "results[['clf', 'round__limit', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train on another dataset and score against ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55752212389380529"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cb_titles = clickbait_titles[0].append(buzzfeedbr_clickbait_titles[\"title\"])\n",
    "df2 = pd.DataFrame({\n",
    "        \"title\": all_cb_titles,\n",
    "        \"is_clickbait\": [1] * len(all_cb_titles)\n",
    "    })\n",
    "\n",
    "all_ncb_titles = non_clickbait_titles[0].append(buzzfeedbr_non_clickbait_titles[\"title\"])\n",
    "df2 = df2.append(pd.DataFrame({\n",
    "        \"title\": all_ncb_titles,\n",
    "        \"is_clickbait\": [0] * len(all_ncb_titles)\n",
    "     }), ignore_index=True)\n",
    "df2 = df2.reindex(np.random.permutation(df2.index))\n",
    "\n",
    "X_train = df2[[\"title\"]]\n",
    "y_train = df2[\"is_clickbait\"]\n",
    "\n",
    "df3 = df[(df[\"is_clickbait\"] == 1) | (df[\"is_clickbait\"] == 0)]\n",
    "df3 = df3.reindex(np.random.permutation(df3.index))\n",
    "\n",
    "X_test = df3[[\"title\"]]\n",
    "y_test = df3[\"is_clickbait\"]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x: x['title'], validate=False)),\n",
    "    ('tfidf', TfidfVectorizer(strip_accents='ascii', ngram_range=(1, 3), max_df=0.5, min_df=5, token_pattern='[A-Za-z0-9]+')),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "clf = pipeline.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant') \n",
      "[CV]  clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant'), total=   4.3s\n",
      "[CV] clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant') \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant'), total=   3.4s\n",
      "[CV] clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant') \n",
      "[CV]  clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant'), total=   3.2s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), total=   3.1s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), total=   3.0s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), total=   3.0s\n",
      "[CV] clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None) \n",
      "[CV]  clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), total=   6.3s\n",
      "[CV] clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None) \n",
      "[CV]  clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), total=   6.4s\n",
      "[CV] clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None) \n",
      "[CV]  clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), total=   6.5s\n",
      "[CV] clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False) \n",
      "[CV]  clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False), total=  54.8s\n",
      "[CV] clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False) \n",
      "[CV]  clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False), total=  53.1s\n",
      "[CV] clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False) \n",
      "[CV]  clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False), total=  49.4s\n",
      "[CV] clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False) \n",
      "[CV]  clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False), total=   7.7s\n",
      "[CV] clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False) \n",
      "[CV]  clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False), total=   7.4s\n",
      "[CV] clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False) \n",
      "[CV]  clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False), total=   7.5s\n",
      "[CV] clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "[CV]  clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), total=   6.3s\n",
      "[CV] clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "[CV]  clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), total=   6.0s\n",
      "[CV] clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "[CV]  clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), total=   6.0s\n",
      "[CV] clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False), total=  17.0s\n",
      "[CV] clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False) \n",
      "[CV]  clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False), total=  16.9s\n",
      "[CV] clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False) \n",
      "[CV]  clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False), total=  17.1s\n",
      "[CV] clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) ..\n",
      "[CV]  clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), total=   2.8s\n",
      "[CV] clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) ..\n",
      "[CV]  clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), total=   2.9s\n",
      "[CV] clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) ..\n",
      "[CV]  clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), total=   3.4s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), total=   3.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), total=   3.0s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), total=   3.3s\n",
      "[CV] clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False), total= 1.4min\n",
      "[CV] clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False), total= 1.4min\n",
      "[CV] clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False), total= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 10.0min finished\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.670003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGDClassifier(alpha=0.0001, average=False, cla...</td>\n",
       "      <td>0.968237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.884506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.910446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.946726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.933223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.874177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.968891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.961380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.0001,...</td>\n",
       "      <td>0.972639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 clf  mean_test_score\n",
       "0  DummyClassifier(constant=1.0, random_state=Non...         0.670003\n",
       "1  SGDClassifier(alpha=0.0001, average=False, cla...         0.968237\n",
       "2  (DecisionTreeClassifier(class_weight=None, cri...         0.884506\n",
       "3  (DecisionTreeClassifier(class_weight=None, cri...         0.910446\n",
       "4  (ExtraTreeClassifier(class_weight=None, criter...         0.946726\n",
       "5  (DecisionTreeClassifier(class_weight=None, cri...         0.933223\n",
       "6  ([DecisionTreeRegressor(criterion='friedman_ms...         0.874177\n",
       "7  MultinomialNB(alpha=1.0, class_prior=None, fit...         0.968891\n",
       "8  LogisticRegression(C=1.0, class_weight=None, d...         0.961380\n",
       "9  MLPClassifier(activation='relu', alpha=0.0001,...         0.972639"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "df4 = df.append(df2, ignore_index=True)\n",
    "\n",
    "positive_df = df4[df4[\"is_clickbait\"] == 1]\n",
    "negative_df = df4[df4[\"is_clickbait\"] == 0].apply(np.random.permutation)[0:len(positive_df)]\n",
    "balanced_df = positive_df.append(negative_df)\n",
    "balanced_df = balanced_df.reindex(np.random.permutation(balanced_df.index))\n",
    "\n",
    "X = balanced_df\n",
    "y = balanced_df[\"is_clickbait\"]\n",
    "y = [ False if yi == 0 else True for yi in y ]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x: x['title'], validate=False)),\n",
    "    ('tfidf', TfidfVectorizer(strip_accents='ascii', ngram_range=(1, 3), max_df=0.5, min_df=2, token_pattern='[A-Za-z0-9]+')),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "clf = GridSearchCV(pipeline, verbose=2, scoring='f1', param_grid={\n",
    "    'clf': [\n",
    "        DummyClassifier(\"constant\", constant=1.0),\n",
    "        SGDClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        ExtraTreesClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        MultinomialNB(),\n",
    "        LogisticRegression(),\n",
    "        MLPClassifier(max_iter=5, early_stopping=True),\n",
    "    ],\n",
    "#     'tfidf__max_df': [0.5, 0.1],\n",
    "#     'tfidf__min_df': [2, 5],\n",
    "#     'tfidf__token_pattern': ['[A-Za-z0-9]+', r\"(?u)\\b\\w\\w+\\b\"]\n",
    "})\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "results = pd.DataFrame(clf.cv_results_)\n",
    "results['clf'] = [ p['clf'] for p in results['params'] ]\n",
    "# results['tfidf__max_df'] = [ p['tfidf__max_df'] for p in results['params'] ]\n",
    "# results['tfidf__min_df'] = [ p['tfidf__min_df'] for p in results['params'] ]\n",
    "# results[['clf', 'tfidf__max_df', 'tfidf__min_df', 'mean_test_score']]\n",
    "results[['clf', 'mean_test_score']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
